{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinli/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras import layers, models\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crowd_data = pd.read_pickle('../data/processed_data_crowd.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 393022 entries, 489 to 222446005\n",
      "Data columns (total 4 columns):\n",
      "project_id    393022 non-null int32\n",
      "src           393022 non-null object\n",
      "attribute     393022 non-null category\n",
      "label         393022 non-null category\n",
      "dtypes: category(2), int32(1), object(1)\n",
      "memory usage: 8.2+ MB\n"
     ]
    }
   ],
   "source": [
    "crowd_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_id</th>\n",
       "      <th>src</th>\n",
       "      <th>attribute</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>40030</td>\n",
       "      <td>https://mir-s3-cdn-cf.behance.net/project_modu...</td>\n",
       "      <td>emotion_peaceful</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>40041</td>\n",
       "      <td>https://mir-s3-cdn-cf.behance.net/project_modu...</td>\n",
       "      <td>emotion_peaceful</td>\n",
       "      <td>unsure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>40041</td>\n",
       "      <td>https://mir-s3-cdn-cf.behance.net/project_modu...</td>\n",
       "      <td>emotion_gloomy</td>\n",
       "      <td>unsure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>40043</td>\n",
       "      <td>https://mir-s3-cdn-cf.behance.net/project_modu...</td>\n",
       "      <td>emotion_peaceful</td>\n",
       "      <td>unsure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>40053</td>\n",
       "      <td>https://mir-s3-cdn-cf.behance.net/project_modu...</td>\n",
       "      <td>media_oilpaint</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      project_id                                                src  \\\n",
       "mid                                                                   \n",
       "489        40030  https://mir-s3-cdn-cf.behance.net/project_modu...   \n",
       "1053       40041  https://mir-s3-cdn-cf.behance.net/project_modu...   \n",
       "1065       40041  https://mir-s3-cdn-cf.behance.net/project_modu...   \n",
       "1067       40043  https://mir-s3-cdn-cf.behance.net/project_modu...   \n",
       "1247       40053  https://mir-s3-cdn-cf.behance.net/project_modu...   \n",
       "\n",
       "             attribute     label  \n",
       "mid                               \n",
       "489   emotion_peaceful  positive  \n",
       "1053  emotion_peaceful    unsure  \n",
       "1065    emotion_gloomy    unsure  \n",
       "1067  emotion_peaceful    unsure  \n",
       "1247    media_oilpaint  negative  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crowd_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 123, 123, 32)      3488      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 62, 62, 32)        128       \n",
      "_________________________________________________________________\n",
      "separable_conv2d_13 (Separab (None, 60, 60, 64)        2400      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "separable_conv2d_14 (Separab (None, 28, 28, 128)       8896      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               3211392   \n",
      "_________________________________________________________________\n",
      "Drop-Out (Dropout)           (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "oil_paint (Dense)            (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 3,227,459\n",
      "Trainable params: 3,227,011\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    input_tensor = Input(shape=(128, 128, 3))\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "        32,\n",
    "        (6, 6),\n",
    "        activation='relu',\n",
    "    )(input_tensor)\n",
    "\n",
    "    x = layers.MaxPool2D(\n",
    "        (2, 2),\n",
    "        padding=\"same\"\n",
    "    )(x)\n",
    "\n",
    "    x = BatchNormalization(\n",
    "    )(x)\n",
    "\n",
    "    x = layers.SeparableConv2D(\n",
    "        64,\n",
    "        3,\n",
    "        activation='relu',\n",
    "    )(x)\n",
    "\n",
    "    x = layers.MaxPool2D(\n",
    "        (2, 2),\n",
    "        padding=\"same\"\n",
    "    )(x)\n",
    "\n",
    "    x = BatchNormalization(\n",
    "    )(x)\n",
    "\n",
    "    x = layers.SeparableConv2D(\n",
    "        128,\n",
    "        3,\n",
    "        activation='relu',\n",
    "    )(x)\n",
    "\n",
    "    x = layers.MaxPool2D(\n",
    "        (2, 2),\n",
    "        padding=\"same\"\n",
    "    )(x)\n",
    "\n",
    "    x = BatchNormalization(\n",
    "    )(x)\n",
    "    #x = inception_module (x)\n",
    "\n",
    "    x = layers.Flatten(\n",
    "    )(x)\n",
    "\n",
    "    x = layers.Dense(\n",
    "        128,\n",
    "        activation='relu',\n",
    "        kernel_regularizer=regularizers.l2(0.001),\n",
    "        #kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001),\n",
    "    )(x)\n",
    "\n",
    "    x = layers.Dropout(\n",
    "        0.5,\n",
    "        name=\"Drop-Out\"\n",
    "    )(x)\n",
    "\n",
    "    water_color_pred = layers.Dense(\n",
    "        100,\n",
    "        activation='softmax',\n",
    "        name='water_color'\n",
    "    )(x)\n",
    "\n",
    "    oil_paint_pred = layers.Dense(\n",
    "        3,\n",
    "        activation='softmax',\n",
    "        name='oil_paint'\n",
    "    )(x)\n",
    "\n",
    "#     model = Model(\n",
    "#         input_tensor,\n",
    "#         [water_color_pred, oil_paint_pred]\n",
    "#     )\n",
    "    model = Model(\n",
    "        input_tensor,\n",
    "        [oil_paint_pred]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 475 images belonging to 3 classes.\n",
      "Found 470 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# data augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    rotation_range=30,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    ")\n",
    "\n",
    "directory = '../data/images/media_oilpaint/'\n",
    "train_dir = directory + 'train'\n",
    "valid_dir = directory + 'valid'\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(128,128),\n",
    "    batch_size=20,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size=(128,128),\n",
    "    batch_size=20,\n",
    "    class_mode=\"categorical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, \\\n",
    "    EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "weight_path = \"{}_weights.best.hdf5\".format('CNN2')\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    weight_path,\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "# tensorboard = TensorBoard(\n",
    "#     log_dir='Logs',\n",
    "    \n",
    "#     # ValueError: If printing histograms, validation_data must be provided, \n",
    "#     #and cannot be a generator.\n",
    "#     #histogram_freq=5, # records activation histogram every n epoch\n",
    "# )\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.2,\n",
    "    patience=1, \n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    min_delta=0.0001, \n",
    "    cooldown=2, \n",
    "    min_lr=1e-7\n",
    ")\n",
    "\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.0001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)  # can place this in call_backs_list\n",
    "\n",
    "early = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    #monitor='acc'\n",
    "    mode=\"min\",\n",
    "    verbose=2,\n",
    "    # training is interrupted when the monitor argument stops improving after n steps\n",
    "    patience=5\n",
    ")\n",
    "\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "20/20 [==============================] - 35s 2s/step - loss: 5.6439 - acc: 0.6158 - val_loss: 6.6663 - val_acc: 0.5717\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 6.66628, saving model to CNN2_weights.best.hdf5\n",
      "Epoch 2/30\n",
      "20/20 [==============================] - 34s 2s/step - loss: 5.6026 - acc: 0.6456 - val_loss: 5.7092 - val_acc: 0.6393\n",
      "\n",
      "Epoch 00002: val_loss improved from 6.66628 to 5.70916, saving model to CNN2_weights.best.hdf5\n",
      "Epoch 3/30\n",
      "20/20 [==============================] - 30s 1s/step - loss: 5.4993 - acc: 0.6511 - val_loss: 5.4340 - val_acc: 0.6769\n",
      "\n",
      "Epoch 00003: val_loss improved from 5.70916 to 5.43398, saving model to CNN2_weights.best.hdf5\n",
      "Epoch 4/30\n",
      "20/20 [==============================] - 27s 1s/step - loss: 6.0468 - acc: 0.6223 - val_loss: 5.8426 - val_acc: 0.6632\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 5.43398\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 5/30\n",
      "20/20 [==============================] - 27s 1s/step - loss: 5.3622 - acc: 0.6700 - val_loss: 5.4433 - val_acc: 0.6872\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 5.43398\n",
      "Epoch 6/30\n",
      "20/20 [==============================] - 27s 1s/step - loss: 5.3495 - acc: 0.6717 - val_loss: 5.5279 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 5.43398\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 7/30\n",
      "20/20 [==============================] - 28s 1s/step - loss: 5.6509 - acc: 0.6600 - val_loss: 5.6090 - val_acc: 0.6717\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 5.43398\n",
      "Epoch 8/30\n",
      "20/20 [==============================] - 28s 1s/step - loss: 5.6954 - acc: 0.6567 - val_loss: 5.5785 - val_acc: 0.6701\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 5.43398\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit_generator(\n",
    "    train_generator,\n",
    "    validation_data=valid_generator,\n",
    "#     steps_per_epoch=round(len(train_images) / batch_size),\n",
    "    steps_per_epoch=20,\n",
    "    epochs=epochs,\n",
    "#     validation_steps=round(len(valid_images) / batch_size),\n",
    "    validation_steps=20,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, os.path\n",
    "# print (len([name for name in os.listdir(train_dir) if os.path.isfile(name)]))\n",
    "neg_len_dir = len (os.listdir(train_dir + '/negative'))\n",
    "pos_len_dir = len (os.listdir(train_dir + '/positive'))\n",
    "uns_len_dir = len (os.listdir(train_dir + '/unsure'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245 86 144\n"
     ]
    }
   ],
   "source": [
    "print (neg_len_dir, pos_len_dir, uns_len_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5157894736842106"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "245 / (245 + 86 + 144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
